<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Seasonality | Nhu Hoang</title>
    <link>/tags/seasonality/</link>
      <atom:link href="/tags/seasonality/index.xml" rel="self" type="application/rss+xml" />
    <description>Seasonality</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2019 Nhu HoangServed by [Netlify](https://geniusnhu.netlify.app/)</copyright><lastBuildDate>Mon, 30 Mar 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/logo_hubeb4088d9e1ef3a12a3be812bce5943c_42313_300x300_fit_lanczos_2.png</url>
      <title>Seasonality</title>
      <link>/tags/seasonality/</link>
    </image>
    
    <item>
      <title>Complete guide for Time series Visualization</title>
      <link>/project/complete-guide-for-time-series-visualization/</link>
      <pubDate>Mon, 30 Mar 2020 00:00:00 +0000</pubDate>
      <guid>/project/complete-guide-for-time-series-visualization/</guid>
      <description>&lt;p&gt;When visualizing time series data, there are several things to be set in mind:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Although we use the same plotting technique as for non-time-series one, but it will not work with the same implication. &lt;strong&gt;Reshaped data&lt;/strong&gt; (aka lag, difference extraction, downsampling, upsampling, etc) is essential.&lt;/li&gt;
&lt;li&gt;It is informative to confirm the &lt;strong&gt;trend, seasonality, cyclic pattern&lt;/strong&gt; as well as &lt;strong&gt;correlation among the series itself (Self-correlation/Autocorrelation) and the series with other series&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Watch out for the &lt;strong&gt;Spurious correlation&lt;/strong&gt;: high correlation is always a trap rather than a prize for data scientist. Many remarks this as &lt;strong&gt;correlation-causation trap&lt;/strong&gt;
. If you observe a &lt;strong&gt;trending and/or seasonal time-series&lt;/strong&gt;, be careful with the correlation. Check if the data is a &lt;strong&gt;cummulative sum&lt;/strong&gt; or not. If it is, spurious correlation is more apt to appear.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The below example with plots will give more details on this.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;1-time-series-patterns&#34;&gt;1. Time series patterns&lt;/h2&gt;
&lt;p&gt;Time series can be describe as the combination of 3 terms: &lt;strong&gt;Trend&lt;/strong&gt;, &lt;strong&gt;Seasonality&lt;/strong&gt; and &lt;strong&gt;Cyclic&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Trend&lt;/strong&gt; is the changeing direction of the series. &lt;strong&gt;Seasonality&lt;/strong&gt; occurs when there is a seasonal factor is seen in the series. &lt;strong&gt;Cyclic&lt;/strong&gt; is similar with Seasonality in term of the repeating cycle of a similar pattern but differs in term of the length nd frequency of the pattern.&lt;/p&gt;
&lt;p&gt;The below graph was plot simply with &lt;code&gt;plot&lt;/code&gt; function of &lt;code&gt;matplotlib&lt;/code&gt;, one of the most common way to observe the series&amp;rsquo; trend, seasonality or cyclic.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;total_sales.png&#34; alt=&#34;&#34; style=&#34;width:60%&#34;&gt;
  &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Looking at the example figure, there is &lt;strong&gt;no trend&lt;/strong&gt; but there is a clear &lt;strong&gt;annual seasonlity&lt;/strong&gt; occured in December. &lt;strong&gt;No cyclic&lt;/strong&gt; as there is no pattern with frequency longer than 1 year.&lt;/p&gt;
&lt;h2 id=&#34;2-confirming-seasonality&#34;&gt;2. Confirming seasonality&lt;/h2&gt;
&lt;p&gt;There are several ways to confirm the seasonlity. Below, I list down vizualization approaches (which is prefered by non-technical people).&lt;/p&gt;
&lt;h3 id=&#34;seasonal-plot&#34;&gt;Seasonal plot:&lt;/h3&gt;
&lt;p&gt;This gives a better prove to spot seasonality, spike and drop. As seen in the below chart, there is a large jump in December, followed by a drop in January.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;seasonal_plot.png&#34; alt=&#34;&#34; style=&#34;width:60%&#34;&gt;
  &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Code can be found below (I am using the new Cyberpunk of Matplotlib, can be found &lt;a href=&#34;https://github.com/dhaitz/mplcyberpunk&#34;&gt;here&lt;/a&gt; with heptic neon color)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;colors = [&#39;#08F7FE&#39;,  # teal/cyan
          &#39;#FE53BB&#39;,  # pink
          &#39;#F5D300&#39;] # matrix green
plt.figure(figsize=(10,6))
w =data.groupby([&#39;Year&#39;,&#39;Month&#39;])[&#39;Weekly_Sales&#39;].sum().reset_index()
sns.lineplot(&amp;quot;Month&amp;quot;, &amp;quot;Weekly_Sales&amp;quot;, data=w, hue=&#39;Year&#39;, palette=colors,marker=&#39;o&#39;, legend=False)
mplcyberpunk.make_lines_glow()
plt.title(&#39;Seasonal plot: Total sales of Walmart 45 stores in 3 years&#39;,fontsize=20 )
plt.legend(title=&#39;Year&#39;, loc=&#39;upper left&#39;, labels=[&#39;2010&#39;, &#39;2011&#39;,&#39;2012&#39;],fontsize=&#39;x-large&#39;, title_fontsize=&#39;20&#39;)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;seasonal-subseries-plot&#34;&gt;Seasonal subseries plot&lt;/h3&gt;
&lt;p&gt;Next is an another way of showing the &lt;strong&gt;distribution&lt;/strong&gt; of time-series data in each month. Insteading of using histogram (which I considered difficult to understand the insight in time series), I generated &lt;em&gt;box plot&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Of note, the main purpose of this plot is to show the &lt;strong&gt;values changing from one month to another&lt;/strong&gt; as well as &lt;strong&gt;how the value distributed within each month&lt;/strong&gt;.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;sub_seasonal.png&#34; alt=&#34;&#34; style=&#34;width:60%&#34;&gt;
  &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;Box plot&lt;/em&gt; is strongly recommended in case of &lt;strong&gt;confirming the mean, median of the seasonal period comparing to other periods&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;3-correlation&#34;&gt;3. Correlation&lt;/h2&gt;
&lt;p&gt;Alike other type of data, &lt;strong&gt;Scatter plot&lt;/strong&gt; stands as the first choice for &lt;strong&gt;identifying the correlation between different time series&lt;/strong&gt;. This is especially the case if one series can be used to explain another series. Below is the correlation of sales and its lag 1.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;scatter.png&#34; alt=&#34;&#34; style=&#34;width:60%&#34;&gt;
  &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data_lag = data.copy()
data_lag[&#39;lag_1&#39;] = data[&#39;Weekly_Sales&#39;].shift(1) # Create lag 1 feature
data_lag.dropna(inplace=True) 

plt.style.use(&amp;quot;cyberpunk&amp;quot;)
plt.figure(figsize=(10,6))
sns.scatterplot(np.log(data_lag.Weekly_Sales), np.log(data_lag.lag_1), data =data_lag)
mplcyberpunk.make_lines_glow()
plt.title(&#39;Weekly sales vs its 1st lag&#39;,fontsize=20 );
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is apparant that the correlation between the original data and its 1&lt;sup&gt;st&lt;/sup&gt; lag is not too strong and there seems some outlier in the top left of the graph.&lt;/p&gt;
&lt;p&gt;It is also interesting to identify if this &lt;em&gt;correlation actually exists and can we use lag 1 to predict the original series&lt;/em&gt;. &lt;strong&gt;The correlation between the original difference and the 1&lt;sup&gt;st&lt;/sup&gt; lag difference&lt;/strong&gt; will give proof for hypothesis.&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;scatter_diff.png&#34; alt=&#34;&#34; style=&#34;width:60%&#34;&gt;
  &lt;figcaption&gt;The correlation between the original difference and the 1&lt;sup&gt;st&lt;/sup&gt; lag difference disappeared, indicating that lag1 does not appear to predict sales.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;data_lag[&#39;lag_1_diff&#39;] = data_lag[&#39;lag_1&#39;].diff() # Create lag 1 difference feature
data_lag[&#39;diff&#39;] = data_lag[&#39;Weekly_Sales&#39;].diff() # Create difference feature
data_lag.dropna(inplace=True) 

plt.style.use(&amp;quot;cyberpunk&amp;quot;)
plt.figure(figsize=(10,6))
sns.scatterplot(data_lag[&#39;diff&#39;], data_lag.lag_1_diff, data =data_lag)
mplcyberpunk.make_lines_glow()
plt.title(&#39;The correlation between original series difference with its 1st lag difference&#39;,fontsize=15);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;moving-average-and-original-series-plot&#34;&gt;Moving average and Original series plot&lt;/h3&gt;
&lt;figure&gt;
  &lt;img src=&#34;moving_average.png&#34; alt=&#34;&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def plotMovingAverage(series, window, plot_intervals=False, scale=1.96, plot_anomalies=False):

    rolling_mean = series.rolling(window=window).mean()
    
    plt.figure(figsize=(15,5))
    plt.title(&amp;quot;Moving average\n window size = {}&amp;quot;.format(window))
    plt.plot(rolling_mean, &amp;quot;g&amp;quot;, label=&amp;quot;Rolling mean trend&amp;quot;)

    # Plot confidence intervals for smoothed values
    if plot_intervals:
        mae = mean_absolute_error(series[window:], rolling_mean[window:])
        deviation = np.std(series[window:] - rolling_mean[window:])
        lower_bond = rolling_mean - (mae + scale * deviation)
        upper_bond = rolling_mean + (mae + scale * deviation)
        plt.plot(upper_bond, &amp;quot;r--&amp;quot;, label=&amp;quot;Upper Bond / Lower Bond&amp;quot;)
        plt.plot(lower_bond, &amp;quot;r--&amp;quot;)
        
        # Having the intervals, find abnormal values
        if plot_anomalies:
            anomalies = pd.DataFrame(index=series.index, columns=series.columns)
            anomalies[series&amp;lt;lower_bond] = series[series&amp;lt;lower_bond]
            anomalies[series&amp;gt;upper_bond] = series[series&amp;gt;upper_bond]
            plt.plot(anomalies, &amp;quot;ro&amp;quot;, markersize=10)
        
    plt.plot(series[window:], label=&amp;quot;Actual values&amp;quot;)
    plt.legend(loc=&amp;quot;upper left&amp;quot;)
    plt.grid(True)
    
plotMovingAverage(series, window, plot_intervals=True, scale=1.96,
                  plot_anomalies=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;acf--pacf-plots-autocorrelation--partial-autocorrelation-plots&#34;&gt;ACF / PACF plots (Autocorrelation / Partial Autocorrelation plots)&lt;/h3&gt;
&lt;p&gt;First, talking about &lt;strong&gt;Autocorrelaltion&lt;/strong&gt;, by definition,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Autocorrelation implies how data points at different points in time are linearly related to one another.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;em&gt;blue area&lt;/em&gt; represents the &lt;em&gt;distance that is not significant than 0&lt;/em&gt; or the &lt;strong&gt;critical region&lt;/strong&gt;, in orther word, the correlation points that &lt;strong&gt;fall beyond this area are significantly different than 0&lt;/strong&gt;, and these the points needed our attention. This region is same for both ACF and PACF, which denoted as $ \pm 1.96\sqrt{n}$&lt;/p&gt;
&lt;p&gt;The details of ACF and PACF plot implication and how to use them for further forecast can be found &lt;a href=&#34;https://geniusnhu.netlify.com/publication/arima-autoregressive-intergreated-moving-average/&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;figure&gt;
  &lt;img src=&#34;ACF_PACF.png&#34; alt=&#34;ACF / PACF plots&#34; style=&#34;width:60%&#34;&gt;
  &lt;figcaption&gt;ACF shows a significant negativve correlation at lag 3 and no positive correlation, indicating that the series has no correlation with its previous values. &lt;br /&gt; PACF reveals that lag 3, lag 6, lag 9, lag 18 and probably lag 19 are important to the original series&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# ACF and PACF for time series data
series=train.dropna()
fig, ax = plt.subplots(2,1, figsize=(10,8))
fig = sm.graphics.tsa.plot_acf(series, lags=None, ax=ax[0])
fig = sm.graphics.tsa.plot_pacf(series, lags=None, ax=ax[1])
plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;actual-vs-predicted-values-plot&#34;&gt;Actual vs Predicted values plot&lt;/h3&gt;
&lt;figure&gt;
  &lt;img src=&#34;actual_predicted.png&#34; alt=&#34;Actual vs Predicted values plot&#34; style=&#34;width:100%&#34;&gt;
  &lt;figcaption&gt;Actual vs Predicted values plot&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def plotModelResults(model, X_train, X_test, y_train, y_test, plot_intervals=False, plot_anomalies=False):

    prediction = model.predict(X_test)
    
    plt.figure(figsize=(12, 8))
    plt.plot(prediction, &amp;quot;g&amp;quot;, label=&amp;quot;prediction&amp;quot;, linewidth=2.0, color=&amp;quot;blue&amp;quot;)
    plt.plot(y_test.values, label=&amp;quot;actual&amp;quot;, linewidth=2.0, color=&amp;quot;olive&amp;quot;)
    
    if plot_intervals:
        cv = cross_val_score(model, X_train, y_train, 
                                    cv=tscv, 
                                    scoring=&amp;quot;neg_mean_absolute_error&amp;quot;)
        mae = cv.mean() * (-1)
        deviation = cv.std()
        
        scale = 1
        lower = prediction - (mae + scale * deviation)
        upper = prediction + (mae + scale * deviation)
        
        plt.plot(lower, &amp;quot;r--&amp;quot;, label=&amp;quot;upper bond / lower bond&amp;quot;, alpha=0.5)
        plt.plot(upper, &amp;quot;r--&amp;quot;, alpha=0.5)
        
        if plot_anomalies:
            anomalies = np.array([np.NaN]*len(y_test))
            anomalies[y_test&amp;lt;lower] = y_test[y_test&amp;lt;lower]
            anomalies[y_test&amp;gt;upper] = y_test[y_test&amp;gt;upper]
            plt.plot(anomalies, &amp;quot;o&amp;quot;, markersize=10, label = &amp;quot;Anomalies&amp;quot;)
    
    error = mean_absolute_percentage_error(y_test,prediction)
    plt.title(&amp;quot;Mean absolute percentage error {0:.2f}%&amp;quot;.format(error))
    plt.legend(loc=&amp;quot;best&amp;quot;)
    plt.tight_layout()
    plt.grid(True);

plotModelResults(linear, X_train, X_test, y_train, y_test,
                 plot_intervals=True, plot_anomalies=True)    
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;To be updated&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
