[{"authors":["admin"],"categories":null,"content":"About me My name is Nhu Hoang, a Data Scientist with current position as Marketing Portfolio Planning Specialist in Amway Japan and a pursuer of beauty in data and insights. I earned Master Degree in Interdisciplinary Studies from Tohoku University, Japan with research on using Regression model to predict the Wind power price and learning curve.\nI own decent foundation and acquired rich experience in Data Science, Machine learning, and analytics within various industries including marketing, digital marketing, and retail. My current focus is tree-based models in applcation of predicting customer behavior.\nMy goal I will be pursuing a Data Scientist career which combines of data utilization with business decision making. I want to implant the power of insights derived from data to business decision through turning complex data science models into practical industrial applications, educating and guiding business to obtain the optimal decisions.\n","date":1581465600,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1581465600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"About me My name is Nhu Hoang, a Data Scientist with current position as Marketing Portfolio Planning Specialist in Amway Japan and a pursuer of beauty in data and insights. I earned Master Degree in Interdisciplinary Studies from Tohoku University, Japan with research on using Regression model to predict the Wind power price and learning curve.\nI own decent foundation and acquired rich experience in Data Science, Machine learning, and analytics within various industries including marketing, digital marketing, and retail.","tags":null,"title":"Nhu Anh Quynh Hoang","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Academic's Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further talk details can easily be added to this page using Markdown and $\\rm \\LaTeX$ math code.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Academic's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":["Nhu Anh Quynh Hoang"],"categories":["Machine Learning"],"content":"My 2020 started awesomely with a Machine Learning Forum @Google Japan and followed with 2 Meetups about Natural Language Processing application. NLP has been the focus of the Machine Learning society for the last decade and it is reaching to its ultimate point with several outbreak of innovations and application.\nAt this moment, 2020, NLP is heading towards speed and big data, which means that the increasing of the speed and size of data is the key objective of future NLP innovations. At the moment, I am impressed with BERT - Bidirectional Encoder Representations from Transformers, a powerful state-of-the-art NPL model introduced by Google in 2018; and *Google Meena, a lift toward dealing with big-NLP database using the Transformer base introducted on Jan 28, 2020.\n1.\tWhy are BERT and Transformer being called the revolution of the NLP world? To understand Transformer model inclduing BERT, we need to take a look of the progress from Seq2Seq (sequence to sequence) and its evolution to attention and to BERT.\n1.1 Seq2Seq model: In NLP, the end that a machine is expected to understand is the meaning of the sentence, not only word by word. Seq2Seq is a technique to train the machine in which it takes a sequence of an item and generates another sequence as output.\nWithin the model, there contains Encoder and Decoder. The Encoder receives the original text and convert the text into a Context vector that the Machine can read. Then, the Decoder does the job of generating a new sequence of items based on the Context vector.\nIn Seq2Seq, a sentence does not need to go through both Encoder and Decoder, it can stop at Encoder. Some example of Encoder only is the suggested word \u0026ldquo;message\u0026rdquo; after you type \u0026ldquo;Thank you for your\u0026rdquo;.\nContext or Context vector is a vector of floats representing the input sequence. \u0026ldquo;Word Embedding\u0026rdquo; is the algorithm used to transform text into vector, and the size of vector is usually 265, 512 or 1024 dimensions.\n1.2 Attention One of the disadvantages of Context in Seq2Seq is the dealing with long sentences and handling the sequence of output. Context is generated by the Word embedding algorithm and the longer the sentence or the paragraph, the bigger the size of vector and the more memory consuming.\nMoreover, the context in Seq2Seq was not built to figure out the similarity between words because it does not focus on the relevancy of the words in the sentence. This leads to the issue that a sentence in English cannot be translated correctly to Japanese which has the reserve order in sentence structure.\nThe concept of Attention was introduced in Bahdanau et al., 2014 and Luong et al., 2015 in which it takes into account the relevant parts in the sentence.\nInstead of passing the last hidden state to the Decoder, the Attention model passes all the hidden states to the Decoder with the summary process as below:\n Give each hidden state a score Use Softmax function to multiply each hidden state. This brings about high Hidden state scores and low hidden state scores or in other word, it generates the probability of each hidden state associating with the input word. The Decoder will sum up all the weighted softmax Hidden state vectors into a context vector and concatenate it with its original hidden state vector.  The advantage of this model is the capability to choose the decoding word based on the probability of that word in associating with the original input without losing the sequential characteristics of the sentence. This has high effectiveness in dealing with translating of common words such as \u0026ldquo;the\u0026rdquo;, \u0026ldquo;his\u0026rdquo;, \u0026ldquo;of\u0026rdquo;, etc. and the sequence of different languages.\n1.3 Transformer: Transformer is built on the foundation of Attention model. Therefore, Transformer can deal with the relevancy of the sentence rather than converting from word to word in Seq2Seq.\nThe biggest difference of Transformer vs Seq2Seq is that instead of generating 1 vector from Encoder, Transformer model uses 3 vectors in order to decide which other parts of the sentence are important (or unimportant) to that word.\nThe below table show more details of the calculation.\n   Word Q vector K vector V vector Score Softmax Sum     First word         I Q1 K1 V1 Q1xK1 S1=Q1xK1/8xV1    love  K2 V2 Q1xK2 S2=Q1xK2/8xV2 Z1 = S1+S2+S3   data  K3 V3 Q1xK3 S3=Q1xK3/8xV3             Second word         I  K1 V1 Q2xK1 S1=Q2xK1/8xV1    love Q2 K2 V2 Q2xK2 S2=Q2xK2/8xV2 Z2 = S1+S2+S3   data  K3 V3 Q2xK3 S3=Q2xK3/8xV3             Third word         I  K1 V1 Q3xK1 S1=Q3xK1/8xV1    love  K2 V2 Q3xK2 S2=Q3xK2/8xV2 Z3 = S1+S2+S3   data Q3 K3 V3 Q3xK3 S3=Q3xK3/8xV3      One example of this model application is the suggestion of relevant words when typing sentence. Gmail can suggest \u0026ldquo;message\u0026rdquo;, \u0026ldquo;reply\u0026rdquo;, \u0026ldquo;call\u0026rdquo; at the same time based on the typed sentence \u0026ldquo;Thank you for your\u0026quot;.\n This is a brief introduction on the transition from Seq2Seq to Transformer and how the Transformer model outstands Seq2Seq at the moment.\n2. Business Applications of NLP   Chatbot: This is obviously the forefront application of NLP, which can be seen across all industries and companies. Given its popularity, there are several tools to support building a chatbot such as Google DialogFlow, Microsoft LUIS. These tools can be customized based on the user's needs; however, they can only deal with simple requests.\n  Machine translation: such as Google translate or pocket translator device.\n  Search engine: 5 years ago, when you searched something on search engine, whether you type key words \u0026ldquo;to Tokyo\u0026rdquo; or the whole sentences \u0026ldquo;How to go to Tokyo\u0026rdquo;, the machine would generate quite similar results. However, with the evolution of BERT and Transformer, searching the whole sentence will throw you to a better search result.\n  Monitoring of brand and product - Sentiment analysis: This is the field that I used to analyze during my first job. I used sentiment analysis on big scale online platforms including online forums, social network, brand website and e-commerce sites to understand the reaction of consumers toward a campaign or a brand in order to react promptly toward negative trend related to the brand.\n  Place to display an advertisement: display ads based on context or categorization and make sure that the article is appropriate at the placing place. Honestly saying, I have not seen much of this application around.\n  Remarketing: an online advertisement based on the browsing history of a user to target them with similar advertising product to drive them back the previous interest. This personalized application is a very effective tool in today online market in which thousands of sellers trying to attract each of their customers. Youtube, Facebook or Google are the biggest applicators.\n  Medical assistant: although called \u0026ldquo;assistant\u0026rdquo;, the major task of this service is to transcript the discussion between doctors and patients.\n  Text generation: this is one of the applications of Decoding in NLP, in which the machine will generate a complete article from what it was learnt or summarize a paragraph. As you may know, there are many contradictions about this application, especially the emergence of fake news in recent years. With the completion of this technology, whether the fake news issue continues its expansion or is stopped is still a big question.\n  Information extraction: extract dynamic required information that is sleeping in the database system.\n  Resume reviews: use NLP to scan the applicants\u0026rsquo; resume to figure out potential candidate for the interview. This application sticks with Amazon big scandal. Amazon used to use this to scan the resume which led to the inequality between male and female with the result preferred male than female. This is due to 0the bias toward male in the training set of the model.\n  Voice command: an emerging technology in recent years with the appearance of smart device such as Siri in Iphone, Alexa of Amazone, Google home or Cortana of Microsoft.\n  Beside the major technological trends mentioned above, the application trend is heading toward diversity in languages and translation efficacy. Moreover, not only applying NLP alone, there are more applications combining NLP and Voice recognition or Computer Vision.\nNLP is a powerful Machine Learning area and its application is supporting human's life even more than we can expect. Therefore, NLP is one of the most used Machine Learning fields by Data Scienctist.\n","date":1581465600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581465600,"objectID":"94ed782a2aa5dd3dc9804ea787823d75","permalink":"/publication/nlp/","publishdate":"2020-02-12T00:00:00Z","relpermalink":"/publication/nlp/","section":"publication","summary":"What is Transformer in today NLP outlook and how does Natural Language Processing contribute to our life","tags":["Natural Language Processing","Data Science","Machine learning","Concept","Application"],"title":"The beauty of Transformer in bringing more applications to life","type":"publication"},{"authors":["Nhu Anh Quynh Hoang"],"categories":["Data Science"],"content":"Have you ever wondered why you, a talented Data Scientist, is not considered as an adviser or a consultant for business, but just a normal employee?\nThis is such a common complaint I heard so many times from my friends, especially the junior. I have also struggled with this issue during the first year of my career but then I successfully overcame it. Now, I realized that this is a real bottleneck of Data Scientist and I think I should share my experience to others so that it will help other Data Scientist achieving a higher reputation for their career.\nThis problem does not only exist in some certain areas but appears everywhere, especially when the scale is tilted toward technical skills rather than keeping balance between business mindset and technical models.\nEven for some senior Data Scientists, this issue is a headache. When I meet others, we spent most of the time talking about a Machine learning models such as RNN, NLP, or advanced and new achievement in applying Data science in the company. However, if I ask them why they decided to use RNN instead of Deep learning and how their model supports the business, they could hardly provide a persuasive reason or they would go with a lengthy explanation on concept, algorithm but forget business aspect.\nI totally do not deny the integral role of technical work of a data scientist, I only want to emphasize the importance of understanding the business concept at first before any other activities.\nHence, I wonder whether they really understand how their models contribute to the business.\nHere I list out a standard flow for starting a data science projects with key point to pay attention to. which I has been applying throughout 4 years working for 2 multinational companies as a data analyst and data scientist.\nAs mentioned above, this post is written based on my experience. Therefore, adjust them to your own situation, and always remember the key concepts so that you will find the most suitable approach for your own work.\n1. First and foremost importance - Clarifying Business question During my years in analytics and data science, in addition to technological concept explanation, business question clarification is one of the most difficult tasks when a Data scientist communicates with business partner.\nI am sure that you here this everywhere, in many articles, that you will always have to clarify business question.\n But how?\n Working is different with researching, especially a Data Scientist is expected to become a wise man who knows the answer for all questions within the business or at least knows how to get the right answers. Therefore, digging the problem is our job and how to do that is our responsibility.\nIt must be very familiar with you when a sales manager asks you \u0026ldquo;I want to know why sales declined?\u0026quot; or a marketing director: \u0026ldquo;How to increase the efficiency of the promotion activity for brand A on our website?\u0026quot;\nWhen you hear these questions, can you imagine the right approach or the answer to the case? Or you will be very vague and keep asking yourself \u0026ldquo;Is that they want me to do this.\u0026rdquo; or \u0026ldquo;I think they want to know that.\u0026quot;, and if you deliver the result based on this understanding, how much confidence you have on your result?\nThe only one response you will get from them is:\n\u0026ldquo;This is not what I need\u0026rdquo;\nOMG! How terrible it is when you spent so much effort into this, but no one values it.\n This is because you did not truly understand problem so that you did not touch the right pain point!\n I know that the common advice is to ask \u0026ldquo;Why\u0026rdquo; in order to dig into the real problems. However, this solution is not applicable all times because the business partners might not know why for all of your questions.\nI usually start by asking about the background of the question, why and how they come up with the request. This is not because I do not understand the business performance but I want to be on the same page with requester and to be able to advise them further on. After asking, many times you will see that the way to deal with the real problem should be different. For example, for the question \u0026ldquo;How to increase the efficiency of the promotion activity for brand A during summer?\u0026quot;, the real issue is not to improve the efficacy of the activity but to optimize the budget spending on online promotion in order to increase the purchase rate and new customers. This is the real question that your business partner wants you to help them answer.\nThen, discuss with the business partner, truly understand on the problem, get alignment on delivery deadline or anything related.\nBe a thinker, not a doer!\n2. Identify the approach for the problem This part is to set the methodology for the analysis.\nThis step requires a broad knowledge on either statistical models or machine learning approached. In some companies, especially non-tech savvy ones, a data scientist is in charge of both analytics and data science work stream.\nThere are numerous models, analysis approaches that you have already learnt and sometimes you will get lost in whether using which types of descriptive analysis, which models of predictive analysis, classification, segmentation, time series forecasting.\n For example: Linear Regression cannot be used to segment customers or Descriptive analysis cannot predict customer churn.\n This step seems to be easy but in fact drives you crazy and confused. If the Sales Director asked Data Science team to forecast the sales for next year, and the business need is to get the forecast based on the amount of budget spending, then which model should be used? If the business wanted the forecast based on the market movement, which approach is suitable?\nThis is the importance in choosing the right approach for the business question.\n3. Acquire the appropriate data After identifying the business questions and the approach above, set up data requirement and extract the appropriate data from the data warehouse are the next thing.\nData selection sounds to be straightforward but indeed complicated. To solve the business questions, which kind of data is in need of. For example, will it need to have the birthday information of the customer if the task is to predict their churn probability?\nThen, identify the approach to acquire the data. This can be from company's data warehouse, conducting survey collecting result, or government-owned data\u0026hellip;\nHowever, what occurs during Data Collection?\nThere are two major problems in this step\n The unavailability of data The bias of training data  First, let's look at the unavailability of data.\nThis problem is very common in real case in which data is unable to capture at the moment of collection such as the time spent in using a non-digital product. As a common sense, you will think that you have to get the data. However, you have to consider the consequences of getting data including cost, time, resources and if the data is indeed not too important to your model, all the effort you put into it will be down the drain.\nTherefore, the solution for this case is to defer inaccessible data and in case the model requires this data for a better result, you will have more resources and confident to invest in obtaining it in the future.\nOn the other hand, one of the provident ways of getting new features is to change the system of collecting data to acquire the right information needed. The Data scientist team can discuss with data management to get the timestamp that customers log on the page in addition to the browsing/ purchasing data.\nIf the Data scientist is unable to acquire unavailable data through the above way, then think about contacting an outside data owner and prepare the budget.\nSecond, the bias of data\nThis problem is serious especially when the training set gets bias from the beginning, the model will learnt accordingly to that bias and results into an inaccuracy prediction when comparing to the real world.\nOne of the most famous flaws of bias in data is the Amazon recruiting AI tool that showed bias against women. The tool reviewed candidate's resumes in order to pick the top talents within them. The tool showed an obvious bias against women because its training data is not gender-neutral from the beginning.\nTherefore, at first hand, be careful with data and its natural distribution are critical responsibility of every Data Scientist.\nAfter getting all the data you need, the next step is thing that a Data scientist usually does:\nThe order can be flexible and this is the standard progress that I usually do in my project and my job. Sometimes, after tuning and the accuracy does not meet my expectation, I need to go back to the feature engineering step to find other way to deal with features.\nThese are the key bottlenecks beside the technical skills that I want to head up for Data Scientist who want to become more than just a Data insight extractor.\n","date":1579996800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579996800,"objectID":"43b28f0c22618d6411e841d0a0ad1c4f","permalink":"/publication/getting-started/","publishdate":"2020-01-26T00:00:00Z","relpermalink":"/publication/getting-started/","section":"publication","summary":"Overcome Data Scientist bottle neck in conducting a Data Science Project in real business context to become a valuable employee'","tags":["Process","Business"],"title":"Practical flow of a Data Science Project","type":"publication"},{"authors":["Nhu Anh Quynh Hoang"],"categories":["Data Science"],"content":"One year ago, when I truly and seriously considered improving my skill in Data Science, two questions were always lingering in my mind:\nWhat truly are the skills that a Data Scientist needs?\nWhat skill will support me in the future and How do I improve myself in the right direction at the most efficacy?\nAnd many other friends, acquaintances reached out to me for a thought of what to learn to become a Data Scientist.\nActually, I can share some of my experiences with them, but as you've already known, this field evolves unpreceedingly fast, technology and new required skills change on the yearly basis at the slowest.\n What you learn today will be the old of tomorrow!\n Luckily, when I was known of the Kaggle dataset on Survey of Data Science and Machine learning, this data will definitely give me some insights for my questions.\nThe Data source is here\nIn this post, I will summary my key findings from the survey. The complete analysis can be found through this link\nThis analysis uses R language with tidyverse package for the best insight visualization.\n Before looking at the result, below are the data cleaning and preparation for the analysis.\n Feature selection:    This dataset includes the written answer of the respondents if they picked \u0026quot;Other\u0026quot; choice for some questions. However, the written answers are stored in another csv file so that all the variables containing \u0026quot;Other\u0026quot; will not a valuable variable for the analysis, therefore they will be excluded from the dataset.\n  For this analysis, the \u0026quot;Duration\u0026quot; variable is not the factor that I want to explore so it will be excluded as well.\n  Other data cleaning:    Shorten some typical column names for easier understanding.\n  Set level for values in the variables that require level later on, such as Company size, Compensation/Salary, year of experience with machine learning\u0026hellip;\n  Create functions for plotting (Example is as below)  plot_df_ds \u0026lt;- function (df_draw_ds, columnName1, columnName2) {\rnames(df_draw_ds)[columnName1] \u0026lt;- paste(\u0026quot;value\u0026quot;)\rnames(df_draw_ds)[columnName2] \u0026lt;- paste(\u0026quot;value2\u0026quot;)\rdf_draw_ds \u0026lt;- df_draw_ds %\u0026gt;% select (value, value2) %\u0026gt;%\rgroup_by(value, value2) %\u0026gt;%\rfilter(value != \u0026quot;Not employed\u0026quot;,value != \u0026quot;Other\u0026quot;) %\u0026gt;% summarise(count=n()) %\u0026gt;% mutate(perc= prop.table(count))\r  Now, let's explore the result.\nRole and Responsibilities: A Data scientist\u0026rsquo; is \u0026lsquo;s responsibility for many tasks with top 3 are:\n  Analyzing data to influence product or to support business decisions\n  Explore new areas of Machine learning through builidng prototypes\n  Experiment to improve company existing Machine learning models\n  Programming skills: Python, SQL and R are all the programming languages that are essential for Data Scientist as they stand in the Top 3 respectively.\nMachine Learning skills: It is not a surprise if all Data Scientists use Machine Learning in their daily job but I was amazed that almost all of them use both Natural Language Processing and Computer Vision. These 2 fields has no longer been specified areas to some groups of users but expanded to much wider application and require Data Scientist to own these skills.\nMachine Learning algorithm skills: Regression and Tree-based algorithms are the models used by Data Scientist. With the long history in statistics and analytics, these models are still being favor in analyzing data. Another advantage of these traditional models is that they are easy to explain to business partner. Other models such as Neuron network, or Deep learning is hard to explain the result.\nAnother interesting thing is that 51% of Data scientists is applying Boosting method.\nPython skills: Scikit-learn, Keras, Xgboost, TensorFlow and RandomForest libraries are the top used frameworks given their benefit and convenience.\nData Scientist Credential: Foundation skills\n  Writing code is an important skill of a good Data scientist. You do not need to be an excellent coder to be a Data scientist but it is dangerous to think that knowing little of coding skill is just enough to work as a Data scientist.\n  It is essential to build up your business skills in addition to technical skills. Many data scientists, especially the junior excels at machine learning and coding but is lack of a business point of view so that most of their work does not support the business as the way it should be. Their recommendations were far from what the company is doing and it ended up beating all of their effort. That is the worst thing you want to face in the world of Data science when no one thinks your idea valuable.\n  Specialized skills\n  Familiar with and expert in Python, SQL and/or R on various online/offline platforms.\n  Fluency in using Local development environments and Intergrated development Environment, including but not limited to Jupyter, RStudio, Pycharm. Try to learn on job or learn on practice.\n  Strong foundation with practical experience in Linear/Logistics regression, Decision Tree/Random Forest, and Gradient Boosting models. Moreover, besides popular and must known libraries such as Scikit-learn, Keras, Tensorflow, Xgboost is the framework that student should learn at the moment. Working on your own project/cooperating project is a good choice to get practical experience if you have not obtained the chance in a company.\n  Computer Vision and NLP are the booming areas in Data science so it is beneficial to prepare yourself with these skills.\n  Although AutoML is a newly emerging field, it will probably become one of the important tools and skills for Data Scientist, including Automated hyperparameter tuning, Data augmentation, Feature engineering/selection and Auto ML pipelines.\n  Skills in working with Big data and Big data products e.g Google Bigquerry, Databricks, Redshift are the must to own.\n  This is the same with usage of cloud computing skills. In big company, it is a common to work on cloud so if you do not know how to conduct machine learning on cloud, it will become your minus comparing to other candidates.\n  And one last important thing: Always believe in yourself, your choice and never give up\nEnd notes As the big survey focusing on the Data science / Machine Learning areas, it appeared as a great source for me to gain valuable information.\nBeside understanding which typical skills requiring to advance in the Data Science field, I want to turn the dataset into a Salary prediction model and I will update on that in upcoming days.\n","date":1579219200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580169600,"objectID":"9a45f9e639dffcb7a0be28261530ca18","permalink":"/2020/01/17/quick-deep-dive-at-data-scientist-skill-set/","publishdate":"2020-01-17T00:00:00Z","relpermalink":"/2020/01/17/quick-deep-dive-at-data-scientist-skill-set/","section":"post","summary":"Skill set that Data Scientist needs to master through studying Kaggle survey 2019 using R'","tags":["Skill","Beginner","Business"],"title":"Quick deep dive at Data Scientist Skill set","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let's make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"}]